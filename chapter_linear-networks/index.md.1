# Linear Neural Networks
:label:`chap_linear`

Before we get into the details of deep neural networks,
we need to cover the basics of neural network training.
In this chapter, we will cover the entire training process,
including defining simple neural network architectures, handling data, specifying a loss function, and training the model. 
In order to make things easier to grasp, we begin with the simplest concepts.
Fortunately, classic statistical learning techniques such as linear and softmax regression
can be cast as *linear* neural networks.
Starting from these classic algorithms, we will introduce you to the basics,
providing the basis for more complex techniques in the rest of the book.

딥 뉴럴 네트워크를 상세하게 알아보기 전에, 뉴럴 네트워크 학습에 대한 기초적인 내용을 알아볼 필요가 있습니다. 이 장에서 우리는 간단한 뉴럴 네트워크 아키텍처 정의, 데이터 다루기, 손실 함수(loss function) 선택, 그리고 모델 학습하기를 포함하는 전체 학습 과정에 대해서 살펴봅니다. 

다행히 선형 또는 소프트맥스(softmax) 회귀와 같은 고전 통계기반의 학습 기법들은 *얕은(shallow)* 뉴럴 네트워크로 취급될 수 있습니다. 우리는 이런 알고리즘들을 출발점으로 기본적인 내용들을 소개할 것이고, 이는 이 책의 나머지 부분들에서 다루는 보다 복잡한 기법을 익히는데 도움이되는 기초가 될 것입니다.

```toc
:maxdepth: 2

linear-regression
linear-regression-scratch
linear-regression-concise
softmax-regression
image-classification-dataset
softmax-regression-scratch
softmax-regression-concise
```

